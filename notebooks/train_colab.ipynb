{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chess RL - AlphaZero Training\n",
    "\n",
    "Train a lightweight AlphaZero-style chess engine using TensorFlow/Keras.\n",
    "\n",
    "**Features:**\n",
    "- 781-dimensional input (bitboards + castling + en passant + side to move)\n",
    "- Lightweight Dense network (~1.4M parameters)\n",
    "- MCTS with PUCT selection\n",
    "- Parallel self-play with batched GPU inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive for checkpoints\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the repository\n",
    "!git clone https://github.com/zhihaohong52/chess-rl.git\n",
    "%cd chess-rl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q python-chess tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify GPU is available\n",
    "import tensorflow as tf\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU available: {tf.config.list_physical_devices('GPU')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/content/chess-rl')\n",
    "\n",
    "from config import Config\n",
    "\n",
    "# Configuration optimized for Colab GPU\n",
    "config = Config()\n",
    "\n",
    "# Checkpoint location\n",
    "config.checkpoint_dir = '/content/drive/MyDrive/chess-rl/checkpoints'\n",
    "\n",
    "# Training parameters\n",
    "config.num_simulations = 50          # MCTS simulations per move\n",
    "config.games_per_iteration = 64      # Games per iteration (more = better GPU usage)\n",
    "config.training_steps = 300          # Training steps per iteration\n",
    "config.buffer_size = 100000          # Replay buffer size\n",
    "config.max_moves = 150               # Max moves per game\n",
    "\n",
    "# Warmup settings (first 10 iterations)\n",
    "config.warmup_simulations = 30\n",
    "config.warmup_games = 64\n",
    "config.main_games = 64\n",
    "\n",
    "# Parallel self-play settings\n",
    "NUM_PARALLEL = 16                    # Games to run in parallel\n",
    "NUM_ITERATIONS = 50                  # Total training iterations\n",
    "\n",
    "print(\"Configuration:\")\n",
    "print(f\"  Simulations per move: {config.num_simulations}\")\n",
    "print(f\"  Games per iteration: {config.games_per_iteration}\")\n",
    "print(f\"  Parallel games: {NUM_PARALLEL}\")\n",
    "print(f\"  Total iterations: {NUM_ITERATIONS}\")\n",
    "print(f\"  Checkpoints: {config.checkpoint_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Initialize Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from src.training.trainer import Trainer\n",
    "\n",
    "# Create checkpoint directory\n",
    "os.makedirs(config.checkpoint_dir, exist_ok=True)\n",
    "\n",
    "# Initialize trainer with parallel self-play\n",
    "trainer = Trainer(\n",
    "    config, \n",
    "    config.checkpoint_dir,\n",
    "    num_parallel=NUM_PARALLEL,    # Run 16 games in parallel\n",
    "    use_parallel=True              # Enable batched GPU inference\n",
    ")\n",
    "\n",
    "print(f\"Network has {trainer.network.trainable_params:,} trainable parameters\")\n",
    "trainer.network.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run training for 50 iterations\n",
    "print(f\"Starting training for {NUM_ITERATIONS} iterations...\")\n",
    "print(f\"Each iteration: {config.games_per_iteration} games, {config.training_steps} training steps\")\n",
    "print(f\"Using parallel self-play with {NUM_PARALLEL} concurrent games\\n\")\n",
    "\n",
    "trainer.train(num_iterations=NUM_ITERATIONS, show_progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.game.chess_game import ChessGame\n",
    "from src.mcts.mcts import MCTS\n",
    "\n",
    "# Play a test game against itself\n",
    "def play_test_game(network, num_simulations=100):\n",
    "    \"\"\"Play a game and show the moves.\"\"\"\n",
    "    game = ChessGame()\n",
    "    mcts = MCTS(network, num_simulations=num_simulations)\n",
    "    \n",
    "    moves = []\n",
    "    while not game.is_terminal() and game.move_count < 100:\n",
    "        action, _ = mcts.get_action(game, temperature=0.1)\n",
    "        if action < 0:\n",
    "            break\n",
    "        move = game.move_encoder.decode(action)\n",
    "        \n",
    "        # Get SAN notation before applying\n",
    "        try:\n",
    "            san = game.board.san(game.board.parse_uci(move.uci()))\n",
    "        except:\n",
    "            san = move.uci()\n",
    "        moves.append(san)\n",
    "        game.apply_move_index(action)\n",
    "    \n",
    "    return moves, game.get_outcome()\n",
    "\n",
    "moves, outcome = play_test_game(trainer.network, num_simulations=100)\n",
    "print(f\"Game result: {'White wins' if outcome > 0 else ('Black wins' if outcome < 0 else 'Draw')}\")\n",
    "print(f\"Total moves: {len(moves)}\")\n",
    "print(f\"Moves: {' '.join(moves[:50])}{'...' if len(moves) > 50 else ''}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show a sample position after 20 moves\n",
    "game = ChessGame()\n",
    "mcts = MCTS(trainer.network, num_simulations=100)\n",
    "\n",
    "for _ in range(20):\n",
    "    if game.is_terminal():\n",
    "        break\n",
    "    action, _ = mcts.get_action(game, temperature=0.1)\n",
    "    if action >= 0:\n",
    "        game.apply_move_index(action)\n",
    "\n",
    "print(game)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Save Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the final model\n",
    "final_path = os.path.join(config.checkpoint_dir, 'model_final')\n",
    "trainer.network.save(final_path)\n",
    "print(f\"Final model saved to: {final_path}.weights.h5\")\n",
    "\n",
    "# Also save as full Keras model\n",
    "keras_path = os.path.join(config.checkpoint_dir, 'model_final.keras')\n",
    "trainer.network.save_full_model(keras_path)\n",
    "print(f\"Full Keras model saved to: {keras_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Resume Training (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To resume training from a checkpoint:\n",
    "# trainer.load_checkpoint()  # Loads latest checkpoint\n",
    "# trainer.train(num_iterations=20)  # Continue training"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
